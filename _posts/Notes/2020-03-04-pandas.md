---
title: Pandas
---

## `DataFrame` Instantiation

- The apply() function works on pd.Series and pd.DataFrame.
  `pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)`

  **data**: 

  - `ndarray` (structured or homogeneous)

  -  `Iterable`: 
    - `List`: `[20, 33, 1]`
    - `List[Dict]`: `[{'col1': 20, 'col2': 'Apple'}, {'col1': 33, 'col2': 'Banana'}, ...]`
  - `dict`: Dict can contain Series, arrays, constants, or list-like objects.
    - e.g. `{'col1': pd.Series([20, 33, 1]), 'col2': ['Apple', 'Banana', 'Cranberry']}`
  -  `DataFrame`

- `DataFrame.from_records(List[Tuple], columns=[...])`

  - e.g. `DataFrame.from_records([(20, 'Apple'), (33, 'Banana'), ...])`
  - also support `structured ndarray, List[Dict]], DataFrame` as `DataFrame.__init__`

- `DataFrame.from_dict()`

  - `DataFrame.from_dict(data, orient='columns')` (default)
  - `DataFrame.from_dict(data, orient='index')`

## Serialization

```python
df.to_records()
```



### List to Series/DataFrame

```python
s = pd.Series(["a", "b", "c"],
              name="vals")
s.to_frame()

s = pd.Series(["a", "b", "c"])
s.to_frame("vals")

df = pd.DataFrame([30, 22, 111], columns=["counts"])
```

## Indexing

```python
df.where( ... == ... )
df[df['名'].str.contains(r"^胡.*心", regex=True, na=False)]
df.query('名 == "胡{璁心"')
df.loc[]
df.iloc[]
df[:, col]
df.shape
```


## Reshaping: Pivot/Groupby/Stack/Unstack/Melt
ref: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.htm
```python
df.pivot(...)

df = pd.DataFrame(dict(zip(['qid', 'amodule', 'atype', 'score', 'pred', 'gold'], [error_ids, error_modules, error_atypes, error_scores, error_preds, error_golds])))
df.groupby('amodule').count()
pt = df.pivot_table(index=['amodule'], columns=['atype'], values=['score'], aggfunc=lambda l: l.to_list())

pt.stack()

pt.unstack()
```

- stack: 
	- col header(data value) moved to the corresponding data element to the index(row) under new column
	- multiindex has 1 one more index
- unstack: 
	- index(row) -> col
	- multiinex


> stack: “pivot” a level of the (possibly hierarchical) column labels, returning a DataFrame with an index with a new inner-most level of row labels.
> unstack: (inverse operation of stack) “pivot” a level of the (possibly hierarchical) row index to the column axis, producing a reshaped DataFrame with a new inner-most level of column labels.

## map/applymap/assign/

- The apply() function works on pd.Series and pd.DataFrame.
  ```python
    df['col1'] = df['col1'].map(complex_function)
      .apply(tuple, axis=1)
  ```
```
  
- `map()` 

  - only works on **`pd.Series`**, 
  - but accepts dict and pd.Series as input. 
  - Using map() with a function is almost interchangeable with using apply(). It can be faster than apply(). 

  ```python
    df['col1'] = df['col1'].map(complex_function)
```

- `applymap()` 

  - is almost identical for **`DataFrame`**s. 
  - *It does not support `pd.Series`* and i
  - t will *always return a `DataFrame`*. 
  - However, it can be faster. The [documentation states](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.applymap.html): "*In the current implementation applymap calls func twice on the first column/row to decide whether it can take a fast or slow code path.*". But if performance really counts you should seek an alternative route.

  ```python
    df['col1'] = df.applymap(complex_function).loc[:, 'col1']
  ```

- `assign()` is not a feasible replacement for apply(). It has a similar behaviour in only the most basic use cases. It does not work with the `complex_function`. You still need apply() as you can see in the example below. The [main use case for assign() is method chaining](https://github.com/pandas-dev/pandas/issues/9229), because it gives back the dataframe without changing the original dataframe.

  ```python
    df['col1'] = df.assign(col1=df.col1.apply(complex_function))
  ```

## get_dummies

### pd.get_dummies

`pd.get_dummies(List/Series/DataFrame, prefix=None, prefix_sep='_', drop_first=False, dummy_na=False, columns=None)`

Convert categorical variable into dummy/indicator variables.

```
s = list('abca')
pd.get_dummies(s)
   a  b  c
0  1  0  0
1  0  1  0
2  0  0  1
3  1  0  0

pd.get_dummies(s1, dummy_na=True)
s1 = ['a', 'b', np.nan]
   a  b
0  1  0
1  0  1
2  0  0

df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],
                   'C': [1, 2, 3]})
pd.get_dummies(df, prefix=['col1', 'col2'])
   C  col1_a  col1_b  col2_a  col2_b  col2_c
0  1       1       0       0       1       0
1  2       0       1       1       0       0
2  3       1       0       0       0       1
```

### pd.Series.str.get_dummies

```python
pd.Series(['a|b', 'a', 'a|c', np.nan]).str.get_dummies(sepstr="|")
   a  b  c
0  1  1  0
1  1  0  0
2  1  0  1
3  0  0  0
```

## Plot

```python
pd.options.plotting.backend = "plotly"

df.plot(kind='...')
df.plot.<kind>

df.plot.line()
df.plot.bar()
df.plot.hist(bins=50)
df.plot.density(bw_method=0.01)  # bandwidth
df.plot.kde()
values=df.<col>.value_counts()
values.plot.pie(autopct=lambda pct: '{:.2f}%  ({:,.0f})'.format(pct, pct * sum(values)/100)).set(title='# xxx of xxx', ylabel='')


import matplotlib.pyplot as plt
counts = [len(df_douyan), len(df_yan_wo_dou), len(df_questions) - len(df_douyan) - len(df_yan_wo_dou)]
labels = ['douyan', '[^dou]yan', 'others']
plt.pie(counts, labels=labels)
plt.title('# QUESTIONS related to douan/yan')
plt.show()


from pandas.plotting import parallel_coordinates
parallel_coordinates(data, 'species', colormap=plt.get_cmap("Set2"))

scipy.stats.describe([...])

import pandas as pd
pd.Series([...]).plot.hist/kde/bar/scatter/pie()
pd.Series([...]).value_counts().plot.bar()
pd.Series([...]).value_counts().sort_index().plot.barh().set(xlabel='...', ylabel='...')

pd.Series([len(s.split(' ')) for s in sents]).plot.hist(bins=20).set(ylabel='# sentences', xlabel='sentence length (words)')
pd.Series([len(s) for s in sents]).plot.hist(bins=20).set(ylabel='# sentences', xlabel='sentence length (characters)')

import numpy as np
counts, edges = np.histogram(filtered_series, bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 50, 100, 200, 300, 400, 500, np.inf])
df = pd.DataFrame({'length': counts}, index=edges[:-1])
df = pd.DataFrame({'length': counts}, index=[f"[{edges[i]:.0f} - {edges[i+1]:.0f})" for i in range(len(counts))])
df.plot.barh()

# remove extreme values
x = pd.Series(np.random.normal(size=size)) # 200 values
x = x[x.between(x.quantile(.15), x.quantile(.85))] # without outliers
```



## Others

```python
df.rename_axis('index_axis_name')
df.rename_axis(index='index_axis_name')
df.rename_axis(columns='column_axis_name')

df.sort_index(ascending=False)

df.describe()
s.describe()

df.reindex(indexorder, columns=columnorder)

df.T

df.sum()

df.iterrows()

# make bins
pd.cut(s, [-0.01] + list(pd.np.arange(max_range)) + [pd.np.inf], labels=False)
```

## Seaborn

```python
df = sns.load_dataset('iris')

cmap = sns.cubehelix_palette(as_cmap=True, light=.9)

sns.violinplot(y=df["species"], x=df["sepal_length"])
sns.kdeplot(df['sepal_width'])
sns.distplot(flights['arr_delay'], 
			hist=True, 
			kde=True, 
			# rug = True,
             bins=int(180/5), 
             color = 'darkblue', 
             hist_kws={'edgecolor':'black'},
             kde_kws={'linewidth': 4})
sns.heatmap(err_df, annot=True, linewidth=1, fmt='.0f', cmap=cmap, **kwargs)
plot.set_facecolor(np.append(cmap.colors[0][:-1], 0.5))
plot.set_xticklabels(plot.get_xticklabels(), rotation=45)

sns.plt.show()
```

## pandas.read_csv

```
pandas.read_csv(
	path,
	names=['col1', 'col2'],
	sep='\t',
	use_col=[0, 1, 3],
	index_col=0|1|...,
)
```



