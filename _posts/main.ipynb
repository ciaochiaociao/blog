{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /home/chiao/.local/lib/python3.6/site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -h --sort=size 開放權威檔/DDBC-Place\n",
    "\n",
    "!tree -h --sort=size 開放權威檔/CBDB-Place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "_filter_empty = lambda s: s != ''\n",
    "filter_empty = lambda l: list(filter(_filter_empty , l))\n",
    "filter_empty(re.split('[()]', '某氏(徐庶母)'))\n",
    "\n",
    "def split_aliases(names):\n",
    "    results = []\n",
    "    for name in names:\n",
    "        try:\n",
    "            results.extend(filter_empty(re.split('[=()（）]', name)))\n",
    "        except TypeError:\n",
    "#             print('TypeError: value - ', name)\n",
    "            pass\n",
    "    return results\n",
    "\n",
    "def get_entities(data_dirpath, col_name):\n",
    "    all_entities = []\n",
    "\n",
    "    for fname in os.listdir(data_dirpath):\n",
    "        fpath = os.path.join(data_dirpath, fname)\n",
    "        if os.path.isdir(fpath):\n",
    "            print(fpath, 'is a directory. Go inside!')\n",
    "            all_entities.extend(get_entities(fpath, col_name))\n",
    "#             pass\n",
    "        elif not os.path.isfile(fpath):\n",
    "            print(fpath, 'is not a file. Skipped')\n",
    "            continue\n",
    "        else:\n",
    "#             print('Processing', fpath, '...')\n",
    "            df = pd.read_excel(fpath)\n",
    "            entities = df[col_name].to_list()\n",
    "            all_entities.extend(split_aliases(entities))\n",
    "    return all_entities\n",
    "\n",
    "def filter_symbols(es):\n",
    "    special_symbols = '！？!?［］[]{}｛｝＠＃＄％︿＆＊＿＋｜＂：﹀＜～／－~@#$%^&*_-+=\\\\|\"\\';:></'\n",
    "\n",
    "    f = lambda e: not (set(e) & set(special_symbols))\n",
    "    return list(filter(f, es))\n",
    "\n",
    "def main(data_dirpath, col_name, segmenter_output_fname, regexner_output_fname, tag, overridden_tag, min_len=2):\n",
    "    all_entities = get_entities(data_dirpath, col_name)\n",
    "    print('(info) total', len(all_entities))\n",
    "    all_entities = filter_symbols(all_entities)\n",
    "    print('(proc) after removing entites with symbols:', len(all_entities))\n",
    "    all_entities = list(set(all_entities))\n",
    "    print('(proc) after removing duplicates:', len(all_entities))\n",
    "    from collections import Counter\n",
    "    print('(info)', Counter(map(len, all_entities)))\n",
    "    df = pd.DataFrame({\"entity\": all_entities, \"tag\": [tag] * len(all_entities), \"override\": [overridden_tag] * len(all_entities)})\n",
    "    print('(proc) built data frame', df.head())\n",
    "    print('(info) long entity', df.query('entity.str.len() > 5').head())\n",
    "    \n",
    "    if min_len:\n",
    "        print(f'(proc) removing length < {min_len}:', df.query(f'entity.str.len() < {min_len}').head())\n",
    "        df = df.query(f'entity.str.len() >= {min_len}')\n",
    "        print('(info)', f'after removing length < {min_len}:', len(df))\n",
    "\n",
    "    df.to_csv(regexner_output_fname, header=None, index=None, sep='\\t')\n",
    "    print(f'(proc) saving file to {regexner_output_fname}...')\n",
    "    df.to_csv(segmenter_output_fname, header=None, index=None, columns=['entity'], sep='\\t')\n",
    "    print(f'(proc) saving file to {segmenter_output_fname}...')\n",
    "    \n",
    "    # copy to inside docker container\n",
    "    print(f'(proc) copying {regexner_output_fname} to inside docker container ...')\n",
    "    !docker cp {regexner_output_fname} corenlp_zh:/stanford-corenlp-full-2018-10-05\n",
    "\n",
    "\n",
    "    print(f'(proc) copying {segmenter_output_fname} to inside docker container ...')\n",
    "    !docker cp {segmenter_output_fname} corenlp_zh:/stanford-corenlp-full-2018-10-05\n",
    "        \n",
    "    # check\n",
    "    print('(check) if existing in local ...')\n",
    "    !head -n 2 {regexner_output_fname}\n",
    "    !wc -l {regexner_output_fname}\n",
    "\n",
    "    !head -n 2 {segmenter_output_fname}\n",
    "    !wc -l {segmenter_output_fname}\n",
    "    \n",
    "    # check in docker\n",
    "    print('(check) if existing in docker container ...')\n",
    "    !docker exec corenlp_zh head -n 2 {regexner_output_fname}\n",
    "    !docker exec corenlp_zh wc -l {regexner_output_fname}\n",
    "\n",
    "    !docker exec corenlp_zh head -n 2 {segmenter_output_fname}\n",
    "    !docker exec corenlp_zh wc -l {segmenter_output_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '開放權威檔'\n",
    "\n",
    "## CBDB-Place\n",
    "\n",
    "# input\n",
    "col_name = '行政區'\n",
    "data_dir = 'CBDB-Place'\n",
    "regexner_output_fname = 'cbdb-gpe-regexner.txt'\n",
    "segmenter_output_fname = 'cbdb-gpe-segmenter.txt'\n",
    "tag = 'GPE'\n",
    "overridden_tag = 'O,PERSON'\n",
    "\n",
    "data_dirpath = os.path.join(root_dir, data_dir)\n",
    "main(data_dirpath, col_name, segmenter_output_fname, regexner_output_fname, tag, overridden_tag)\n",
    "\n",
    "## DDBC-Place\n",
    "\n",
    "col_name = '名'\n",
    "data_dir = 'DDBC-Place'\n",
    "regexner_output_fname = 'ddbc-place-regexner.txt'\n",
    "segmenter_output_fname = 'ddbc-place-segmenter.txt'\n",
    "tag = 'LOCATION'\n",
    "overridden_tag = 'O,PERSON'\n",
    "data_dirpath = os.path.join(root_dir, data_dir)\n",
    "main(data_dirpath, col_name, segmenter_output_fname, regexner_output_fname, tag, overridden_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate properties file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexner_files = ['cbdb-person-regexner.txt', 'ddbc-person-regexner.txt', 'cbdb-gpe-regexner.txt', 'ddbc-place-regexner.txt']\n",
    "segmenter_files = ['cbdb-person-segmenter.txt', 'ddbc-person-segmenter.txt', 'cbdb-gpe-segmenter.txt', 'ddbc-place-segmenter.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "props_inpath = 'StanfordCoreNLP-chinese-fgc-template.properties'\n",
    "props_outpath = 'StanfordCoreNLP-chinese-fgc.properties'\n",
    "\n",
    "print('(proc) generating properties file ...')\n",
    "!cp {props_inpath} {props_outpath}\n",
    "\n",
    "old_str = '#ner.additional.regexner.mapping = ...'\n",
    "new_str = 'ner.additional.regexner.mapping = ' + ','.join(regexner_files)\n",
    "!sed -i 's/{old_str}/{new_str}/g' {props_outpath}\n",
    "\n",
    "old_str = 'segment.serDictionary = edu\\/stanford\\/nlp\\/models\\/segmenter\\/chinese\\/dict-chris6.ser.gz'\n",
    "new_str = old_str + ',' + ','.join(segmenter_files)\n",
    "!sed -i 's/{old_str}/{new_str}/g' {props_outpath}\n",
    "\n",
    "print('(modified part)')\n",
    "!diff --color {props_inpath} {props_outpath}\n",
    "\n",
    "print('(proc) moving to docker container')\n",
    "!docker cp {props_outpath} corenlp_zh:/stanford-corenlp-full-2018-10-05/{props_outpath}\n",
    "print('(check) if moved')\n",
    "!docker exec corenlp_zh grep 'segment.serDictionary' {props_outpath}\n",
    "!docker exec corenlp_zh grep 'ner.additional.regexner.mapping' {props_outpath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart CoreNLPServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(proc) starting a new server\n",
      "   11 root      0:00 java -mx8g -cp * edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000 -serverProperties StanfordCoreNLP-chinese-fgc.properties\n"
     ]
    }
   ],
   "source": [
    "# kill existent server\n",
    "ps_str = !docker exec corenlp_zh ps | grep StanfordCoreNLPServer\n",
    "if ps_str:\n",
    "    print('(proc) killing server ps:', ps_str[0])\n",
    "    pid = int(ps_str[0].strip().split(' ')[0])\n",
    "    p = !docker exec corenlp_zh kill {pid} && ps | grep StanfordCoreNLPServer\n",
    "    assert not p, p\n",
    "\n",
    "# start a new server\n",
    "print('(proc) starting a new server')\n",
    "!docker exec -d corenlp_zh ash -c \"java -mx8g -cp '*' edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000 -serverProperties StanfordCoreNLP-chinese-fgc.properties &> run.log\" && docker exec corenlp_zh ps -a | grep StanfordCoreNLPServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanfordnlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/bf/5d2898febb6e993fcccd90484cba3c46353658511a41430012e901824e94/stanfordnlp-0.2.0-py3-none-any.whl (158kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 189kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf (from stanfordnlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f1/8dcd4219bbae8aa44fe8871a89f05eca2dca9c04f8dbfed8a82b7be97a88/protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 71.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/chiao/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (4.36.1)\n",
      "Requirement already satisfied: numpy in /home/chiao/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (1.17.2)\n",
      "Requirement already satisfied: requests in /home/chiao/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (2.22.0)\n",
      "Collecting torch>=1.0.0 (from stanfordnlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4MB 6.7kB/s eta 0:00:010   |▏                               | 4.2MB 48.6MB/s eta 0:00:16\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9 in /home/chiao/anaconda3/lib/python3.7/site-packages (from protobuf->stanfordnlp) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/chiao/anaconda3/lib/python3.7/site-packages (from protobuf->stanfordnlp) (41.4.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/chiao/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/chiao/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/chiao/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/chiao/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (2.8)\n",
      "Installing collected packages: protobuf, torch, stanfordnlp\n",
      "Successfully installed protobuf-3.11.3 stanfordnlp-0.2.0 torch-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../wiki_kb_inference')\n",
    "from stanfordnlp_utils import *\n",
    "from fgc_utils import *\n",
    "from utils import load_json\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from stanfordnlp.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_json('../wiki_kb_inference/FGC_release_all(cn).json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DID': 'D001',\n",
       " 'DTEXT': '蘇軾（1037年1月8日－1101年8月24日），眉州眉山（今四川省眉山市）人，北宋時著名的文學家、政治家、藝術家、醫學家。字子瞻，一字和仲，號東坡居士、鐵冠道人。嘉佑二年進士，累官至端明殿學士兼翰林學士，禮部尚書。南宋理學方熾時，加賜諡號文忠，複追贈太師。有《東坡先生大全集》及《東坡樂府》詞集傳世，宋人王宗稷收其作品，編有《蘇文忠公全集》。\\n其散文、詩、詞、賦均有成就，且善書法和繪畫，是文學藝術史上的通才，也是公認韻文散文造詣皆比較傑出的大家。蘇軾的散文為唐宋四家（韓愈、柳宗元、歐蘇）之末，與唐代的古文運動發起者韓愈並稱為「韓潮蘇海」，也與歐陽修並稱「歐蘇」；更與父親蘇洵、弟蘇轍合稱「三蘇」，父子三人，同列唐宋八大家。蘇軾之詩與黃庭堅並稱「蘇黃」，又與陸游並稱「蘇陸」；其詞「以詩入詞」，首開詞壇「豪放」一派，振作了晚唐、五代以來綺靡的西崑體餘風。後世與南宋辛棄疾並稱「蘇辛」，惟蘇軾故作豪放，其實清朗；其賦亦頗有名氣，最知名者為貶謫期間借題發揮寫的前後《赤壁賦》。宋代每逢科考常出現其文命題之考試，故當時學者曰：「蘇文熟，喫羊肉、蘇文生，嚼菜羹」。藝術方面，書法名列「蘇、黃、米、蔡」北宋四大書法家（宋四家）之首；其畫則開創了湖州畫派；並在題畫文學史上佔有舉足輕重的地位。',\n",
       " 'QUESTIONS': [{'QID': 'D001Q01',\n",
       "   'QTYPE': '基础题',\n",
       "   'QTEXT': '蘇東坡在中國歷史上，是哪一個朝代的人？',\n",
       "   'SENTS': [{'text': '苏东坡在中国历史上，', 'start': 0, 'end': 10},\n",
       "    {'text': '是哪一个朝代的人？', 'start': 10, 'end': 19}],\n",
       "   'ANSWER': [{'ATEXT': '北宋',\n",
       "     'ATOKEN': [{'text': '北宋', 'start': 40}],\n",
       "     'ATEXT_CN': '北宋'}],\n",
       "   'ATYPE': 'Date-Duration',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [{'text': '苏轼', 'start': 0, 'end': 2},\n",
       "    {'text': '东坡居士', 'start': 72, 'end': 76},\n",
       "    {'text': '北宋', 'start': 40, 'end': 42}],\n",
       "   'SHINT': [0, 2, 4],\n",
       "   'QTEXT_CN': '苏东坡在中国历史上，是哪一个朝代的人？'},\n",
       "  {'QID': 'D001Q02',\n",
       "   'QTYPE': '基础题',\n",
       "   'QTEXT': '蘇東坡是中國哪個省份的人？',\n",
       "   'SENTS': [{'text': '苏东坡是中国哪个省份的人？', 'start': 0, 'end': 13}],\n",
       "   'ANSWER': [{'ATEXT': '四川省',\n",
       "     'ATOKEN': [{'text': '四川省', 'start': 31}],\n",
       "     'ATEXT_CN': '四川省'}],\n",
       "   'ATYPE': 'Location',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [{'text': '苏轼', 'start': 0, 'end': 2},\n",
       "    {'text': '四川省', 'start': 31, 'end': 34},\n",
       "    {'text': '东坡居士', 'start': 72, 'end': 76}],\n",
       "   'SHINT': [0, 1, 4],\n",
       "   'QTEXT_CN': '苏东坡是中国哪个省份的人？'},\n",
       "  {'QID': 'D001Q03',\n",
       "   'QTYPE': '基础题',\n",
       "   'QTEXT': '蘇東坡的爸爸叫什麼名字?',\n",
       "   'SENTS': [{'text': '苏东坡的爸爸叫什么名字?', 'start': 0, 'end': 12}],\n",
       "   'ANSWER': [{'ATEXT': '蘇洵',\n",
       "     'ATOKEN': [{'text': '苏洵', 'start': 288}],\n",
       "     'ATEXT_CN': '苏洵'}],\n",
       "   'ATYPE': 'Person',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [{'text': '苏轼', 'start': 0, 'end': 2},\n",
       "    {'text': '东坡居士', 'start': 72, 'end': 76},\n",
       "    {'text': '苏轼', 'start': 225, 'end': 227},\n",
       "    {'text': '苏洵', 'start': 288, 'end': 290}],\n",
       "   'SHINT': [0, 4, 17, 20],\n",
       "   'QTEXT_CN': '苏东坡的爸爸叫什么名字?'},\n",
       "  {'QID': 'D001Q04',\n",
       "   'QTYPE': '进阶题',\n",
       "   'QTEXT': '蘇文忠公指的是誰?',\n",
       "   'SENTS': [{'text': '苏文忠公指的是谁?', 'start': 0, 'end': 9}],\n",
       "   'ANSWER': [{'ATEXT': '蘇軾',\n",
       "     'ATOKEN': [{'text': '苏轼', 'start': 0}],\n",
       "     'ATEXT_CN': '苏轼'}],\n",
       "   'ATYPE': 'Person',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [{'text': '苏轼', 'start': 0, 'end': 2},\n",
       "    {'text': '文忠', 'start': 120, 'end': 122}],\n",
       "   'SHINT': [0, 8],\n",
       "   'QTEXT_CN': '苏文忠公指的是谁?'},\n",
       "  {'QID': 'D001Q05',\n",
       "   'QTYPE': '基础题',\n",
       "   'QTEXT': '《蘇文忠公全集》是由何人編纂？',\n",
       "   'SENTS': [{'text': '《苏文忠公全集》是由何人编纂？', 'start': 0, 'end': 15}],\n",
       "   'ANSWER': [{'ATEXT': '王宗稷',\n",
       "     'ATOKEN': [{'text': '王宗稷', 'start': 153}],\n",
       "     'ATEXT_CN': '王宗稷'}],\n",
       "   'ATYPE': 'Person',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [{'text': '苏文忠公全集', 'start': 164, 'end': 170},\n",
       "    {'text': '王宗稷', 'start': 153, 'end': 156}],\n",
       "   'SHINT': [11, 12],\n",
       "   'QTEXT_CN': '《苏文忠公全集》是由何人编纂？'},\n",
       "  {'QID': 'D001Q06',\n",
       "   'QTYPE': '进阶题',\n",
       "   'QTEXT': '韓愈在中國歷史上，是哪一個朝代的人？',\n",
       "   'SENTS': [{'text': '韩愈在中国历史上，', 'start': 0, 'end': 9},\n",
       "    {'text': '是哪一个朝代的人？', 'start': 9, 'end': 18}],\n",
       "   'ANSWER': [{'ATEXT': '唐代',\n",
       "     'ATOKEN': [{'text': '唐代', 'start': 250}],\n",
       "     'ATEXT_CN': '唐代'}],\n",
       "   'ATYPE': 'Date-Duration',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [{'text': '唐代', 'start': 250, 'end': 252},\n",
       "    {'text': '韩愈', 'start': 260, 'end': 262}],\n",
       "   'SHINT': [18],\n",
       "   'QTEXT_CN': '韩愈在中国历史上，是哪一个朝代的人？'},\n",
       "  {'QID': 'D001Q07',\n",
       "   'QTYPE': '进阶题',\n",
       "   'QTEXT': '蘇東坡與韓愈是否為好朋友?',\n",
       "   'SENTS': [{'text': '苏东坡与韩愈是否为好朋友?', 'start': 0, 'end': 13}],\n",
       "   'ANSWER': [{'ATEXT': '否',\n",
       "     'ATOKEN': [{'text': '否', 'start': -1}],\n",
       "     'ATEXT_CN': '否'}],\n",
       "   'ATYPE': 'YesNo',\n",
       "   'AMODE': 'YesNo',\n",
       "   'ASPAN': [{'text': '唐代', 'start': 250, 'end': 252},\n",
       "    {'text': '韩愈', 'start': 260, 'end': 262},\n",
       "    {'text': '苏轼', 'start': 0, 'end': 2},\n",
       "    {'text': '北宋', 'start': 40, 'end': 42},\n",
       "    {'text': '东坡居士', 'start': 72, 'end': 76}],\n",
       "   'SHINT': [0, 2, 4, 18],\n",
       "   'QTEXT_CN': '苏东坡与韩愈是否为好朋友?'},\n",
       "  {'QID': 'D001Q08',\n",
       "   'QTYPE': '进阶题',\n",
       "   'QTEXT': '蘇東坡曾擔任過哪些職位?',\n",
       "   'SENTS': [{'text': '苏东坡曾担任过哪些职位?', 'start': 0, 'end': 12}],\n",
       "   'ANSWER': [{'ATEXT': '端明殿學士、翰林學士及禮部尚書',\n",
       "     'ATOKEN': [{'text': '端明殿学士', 'start': 92},\n",
       "      {'text': '翰林学士', 'start': 98},\n",
       "      {'text': '礼部尚书', 'start': 103}],\n",
       "     'ATEXT_CN': '端明殿学士、翰林学士及礼部尚书'}],\n",
       "   'ATYPE': 'Organization',\n",
       "   'AMODE': 'Multi-Spans-Extraction',\n",
       "   'ASPAN': [{'text': '苏轼', 'start': 0, 'end': 2},\n",
       "    {'text': '东坡居士', 'start': 72, 'end': 76},\n",
       "    {'text': '端明殿学士', 'start': 92, 'end': 97},\n",
       "    {'text': '翰林学士', 'start': 98, 'end': 102},\n",
       "    {'text': '礼部尚书', 'start': 103, 'end': 107}],\n",
       "   'SHINT': [0, 4, 6, 7],\n",
       "   'QTEXT_CN': '苏东坡曾担任过哪些职位?'},\n",
       "  {'QID': 'D001Q09',\n",
       "   'QTYPE': '基础题',\n",
       "   'QTEXT': '辛棄疾是哪一個朝代的人？',\n",
       "   'SENTS': [{'text': '辛弃疾是哪一个朝代的人？', 'start': 0, 'end': 12}],\n",
       "   'ANSWER': [{'ATEXT': '南宋',\n",
       "     'ATOKEN': [{'text': '南宋', 'start': 108}],\n",
       "     'ATEXT_CN': '南宋'}],\n",
       "   'ATYPE': 'Date-Duration',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [{'text': '辛弃疾', 'start': 384, 'end': 387},\n",
       "    {'text': '南宋', 'start': 382, 'end': 384}],\n",
       "   'SHINT': [27],\n",
       "   'QTEXT_CN': '辛弃疾是哪一个朝代的人？'},\n",
       "  {'QID': 'D001Q11',\n",
       "   'QTYPE': '申论',\n",
       "   'QTEXT': '蘇東坡為何被後人認為是文學藝術史上的通才?',\n",
       "   'SENTS': [{'text': '苏东坡为何被后人认为是文学艺术史上的通才?', 'start': 0, 'end': 21}],\n",
       "   'ANSWER': [{'ATEXT': '',\n",
       "     'ATOKEN': [{'text': '', 'start': 0}],\n",
       "     'ATEXT_CN': ''}],\n",
       "   'ATYPE': 'Event',\n",
       "   'AMODE': 'Single-Span-Extraction',\n",
       "   'ASPAN': [],\n",
       "   'SHINT': [],\n",
       "   'QTEXT_CN': '苏东坡为何被后人认为是文学艺术史上的通才?'}],\n",
       " 'SENTS': [{'text': '苏轼（1037年1月8日－1101年8月24日），', 'start': 0, 'end': 25},\n",
       "  {'text': '眉州眉山（今四川省眉山市）人，', 'start': 25, 'end': 40},\n",
       "  {'text': '北宋时著名的文学家、政治家、艺术家、医学家。', 'start': 40, 'end': 62},\n",
       "  {'text': '字子瞻，一字和仲，', 'start': 62, 'end': 71},\n",
       "  {'text': '号东坡居士、铁冠道人。', 'start': 71, 'end': 82},\n",
       "  {'text': '嘉佑二年进士，', 'start': 82, 'end': 89},\n",
       "  {'text': '累官至端明殿学士兼翰林学士，', 'start': 89, 'end': 103},\n",
       "  {'text': '礼部尚书。南宋理学方炽时，', 'start': 103, 'end': 116},\n",
       "  {'text': '加赐谥号文忠，', 'start': 116, 'end': 123},\n",
       "  {'text': '复追赠太师。', 'start': 123, 'end': 129},\n",
       "  {'text': '有《东坡先生大全集》及《东坡乐府》词集传世，', 'start': 129, 'end': 151},\n",
       "  {'text': '宋人王宗稷收其作品，', 'start': 151, 'end': 161},\n",
       "  {'text': '编有《苏文忠公全集》。', 'start': 161, 'end': 172},\n",
       "  {'text': '\\n其散文、诗、词、赋均有成就，', 'start': 172, 'end': 187},\n",
       "  {'text': '且善书法和绘画，', 'start': 187, 'end': 195},\n",
       "  {'text': '是文学艺术史上的通才，', 'start': 195, 'end': 206},\n",
       "  {'text': '也是公认韵文散文造诣皆比较杰出的大家。', 'start': 206, 'end': 225},\n",
       "  {'text': '苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，', 'start': 225, 'end': 249},\n",
       "  {'text': '与唐代的古文运动发起者韩愈并称为「韩潮苏海」，', 'start': 249, 'end': 272},\n",
       "  {'text': '也与欧阳修并称「欧苏」；', 'start': 272, 'end': 284},\n",
       "  {'text': '更与父亲苏洵、弟苏辙合称「三苏」，', 'start': 284, 'end': 301},\n",
       "  {'text': '父子三人，同列唐宋八大家。', 'start': 301, 'end': 314},\n",
       "  {'text': '苏轼之诗与黄庭坚并称「苏黄」，', 'start': 314, 'end': 329},\n",
       "  {'text': '又与陆游并称「苏陆」；', 'start': 329, 'end': 340},\n",
       "  {'text': '其词「以诗入词」，', 'start': 340, 'end': 349},\n",
       "  {'text': '首开词坛「豪放」一派，', 'start': 349, 'end': 360},\n",
       "  {'text': '振作了晚唐、五代以来绮靡的西昆体余风。', 'start': 360, 'end': 379},\n",
       "  {'text': '后世与南宋辛弃疾并称「苏辛」，', 'start': 379, 'end': 394},\n",
       "  {'text': '惟苏轼故作豪放，', 'start': 394, 'end': 402},\n",
       "  {'text': '其实清朗；其赋亦颇有名气，', 'start': 402, 'end': 415},\n",
       "  {'text': '最知名者为贬谪期间借题发挥写的前后《赤壁赋》。', 'start': 415, 'end': 438},\n",
       "  {'text': '宋代每逢科考常出现其文命题之考试，', 'start': 438, 'end': 455},\n",
       "  {'text': '故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。', 'start': 455, 'end': 480},\n",
       "  {'text': '艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；', 'start': 480, 'end': 513},\n",
       "  {'text': '其画则开创了湖州画派；', 'start': 513, 'end': 524},\n",
       "  {'text': '并在题画文学史上占有举足轻重的地位。', 'start': 524, 'end': 542}],\n",
       " 'DTEXT_CN': '苏轼（1037年1月8日－1101年8月24日），眉州眉山（今四川省眉山市）人，北宋时著名的文学家、政治家、艺术家、医学家。字子瞻，一字和仲，号东坡居士、铁冠道人。嘉佑二年进士，累官至端明殿学士兼翰林学士，礼部尚书。南宋理学方炽时，加赐谥号文忠，复追赠太师。有《东坡先生大全集》及《东坡乐府》词集传世，宋人王宗稷收其作品，编有《苏文忠公全集》。\\n其散文、诗、词、赋均有成就，且善书法和绘画，是文学艺术史上的通才，也是公认韵文散文造诣皆比较杰出的大家。苏轼的散文为唐宋四家（韩愈、柳宗元、欧苏）之末，与唐代的古文运动发起者韩愈并称为「韩潮苏海」，也与欧阳修并称「欧苏」；更与父亲苏洵、弟苏辙合称「三苏」，父子三人，同列唐宋八大家。苏轼之诗与黄庭坚并称「苏黄」，又与陆游并称「苏陆」；其词「以诗入词」，首开词坛「豪放」一派，振作了晚唐、五代以来绮靡的西昆体余风。后世与南宋辛弃疾并称「苏辛」，惟苏轼故作豪放，其实清朗；其赋亦颇有名气，最知名者为贬谪期间借题发挥写的前后《赤壁赋》。宋代每逢科考常出现其文命题之考试，故当时学者曰：「苏文熟，吃羊肉、苏文生，嚼菜羹」。艺术方面，书法名列「苏、黄、米、蔡」北宋四大书法家（宋四家）之首；其画则开创了湖州画派；并在题画文学史上占有举足轻重的地位。'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dids = [doc['DID'] for doc in docs]\n",
    "get_doc(dids[0], docs)\n",
    "# dids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d710c7036b9400ca49839c3607e62f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='did', options=('D001', 'D002', 'D003', 'D004', 'D006', 'D007', 'D0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "@interact_manual\n",
    "def pretty_corenlp(did=dids):\n",
    "    doc_dic = get_doc(did, docs)\n",
    "    print('[New]')\n",
    "    with CoreNLPClient(endpoint='http://localhost:9000', start_server=False) as nlp:\n",
    "        doc = nlp.annotate(doc_dic['DTEXT_CN'], properties={'ssplit.boundaryTokenRegex': '[。]|[!?！？]+'})\n",
    "\n",
    "        for sent in doc.sentence:\n",
    "            print(f'(s{sent.sentenceIndex})', end=' ')\n",
    "            snp_pprint(sent, mode='custom', classes_w_color=['PERSON', 'GPE', 'LOCATION', 'MISC', 'TITLE'])\n",
    "    print('-----------------------------------------------------')\n",
    "    print('[Old]')\n",
    "    with CoreNLPClient(endpoint='http://140.109.19.191:9000', start_server=False) as nlp:\n",
    "        doc = nlp.annotate(doc_dic['DTEXT_CN'], properties={'ssplit.boundaryTokenRegex': '[。]|[!?！？]+',\n",
    "                                                            'pipelineLanguage': 'zh'})\n",
    "\n",
    "        for sent in doc.sentence:\n",
    "            print(f'(s{sent.sentenceIndex})', end=' ')\n",
    "            snp_pprint(sent, mode='custom', classes_w_color=['PERSON', 'GPE', 'LOCATION', 'MISC', 'TITLE'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s0) "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a9770860473c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'(s{sent.sentenceIndex})'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msnp_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/d/wiki_kb_inference/stanfordnlp_utils.py\u001b[0m in \u001b[0;36msnp_pprint\u001b[0;34m(snp_sent, mode, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     }\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'color'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mprint_multicolor_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'custom'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mprint_multicolor_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/d/wiki_kb_inference/utils.py\u001b[0m in \u001b[0;36mprint_multicolor_strs\u001b[0;34m(strs, strs_class, color_table, all_classes, classes_w_color, classes_wo_color, colors, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mclasses_w_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_wo_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mnum_classes_w_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_w_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mnum_classes_wo_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_wo_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnum_classes_w_color\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_classes_wo_color\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "nlp = CoreNLPClient(endpoint='http://140.109.19.191:9000', start_server=False)\n",
    "\n",
    "doc = nlp.annotate(docs[0]['DTEXT_CN'],properties={'ssplit.boundaryTokenRegex': '[。]|[!?！？]+',\n",
    "                                                    'pipelineLanguage': 'zh'},\n",
    "                  annotators='tokenize,ssplit,pos,lemma,ner,depparse,parse,coref,entitylink')\n",
    "\n",
    "for sent in doc.sentence:\n",
    "    print(f'(s{sent.sentenceIndex})', end=' ')\n",
    "    snp_pprint(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s0) "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-953e3248eb41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'(s{sent.sentenceIndex})'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msnp_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/d/wiki_kb_inference/stanfordnlp_utils.py\u001b[0m in \u001b[0;36msnp_pprint\u001b[0;34m(snp_sent, mode, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     }\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'color'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mprint_multicolor_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'custom'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mprint_multicolor_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/d/wiki_kb_inference/utils.py\u001b[0m in \u001b[0;36mprint_multicolor_strs\u001b[0;34m(strs, strs_class, color_table, all_classes, classes_w_color, classes_wo_color, colors, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mclasses_w_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_wo_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mnum_classes_w_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_w_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mnum_classes_wo_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_wo_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnum_classes_w_color\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_classes_wo_color\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "nlp = CoreNLPClient(endpoint='http://localhost:9000', start_server=False)\n",
    "\n",
    "doc = nlp.annotate(docs[3]['DTEXT_CN'], properties={'ssplit.boundaryTokenRegex': '[。]|[!?！？]+'})\n",
    "\n",
    "for sent in doc.sentence:\n",
    "    print(f'(s{sent.sentenceIndex})', end=' ')\n",
    "    snp_pprint(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s0) \u001b[35m元\u001b[0m \u001b[35m祐\u001b[0m \u001b[44m元年\u001b[0m \u001b[39m（\u001b[0m \u001b[44m1086年\u001b[0m \u001b[39m）\u001b[0m \u001b[39m，\u001b[0m \u001b[41m宋哲宗\u001b[0m \u001b[39m即位\u001b[0m \u001b[39m，\u001b[0m \u001b[39m高\u001b[0m \u001b[39m太\u001b[0m \u001b[39m皇太\u001b[0m \u001b[39m后\u001b[0m \u001b[39m垂帘听政\u001b[0m \u001b[39m，\u001b[0m \u001b[39m回朝\u001b[0m \u001b[39m任\u001b[0m \u001b[45m礼部\u001b[0m \u001b[45m郎中\u001b[0m \u001b[39m、\u001b[0m \u001b[1;40m中书舍人\u001b[0m \u001b[39m、\u001b[0m \u001b[39m翰林\u001b[0m \u001b[39m学士\u001b[0m \u001b[39m，\u001b[0m \u001b[35m元祐\u001b[0m \u001b[33m四\u001b[0m \u001b[35m年\u001b[0m \u001b[39m（\u001b[0m \u001b[44m1089年\u001b[0m \u001b[39m）\u001b[0m \u001b[39m拜\u001b[0m \u001b[39m龙图阁\u001b[0m \u001b[39m学士\u001b[0m \u001b[39m，\u001b[0m \u001b[39m曾\u001b[0m \u001b[39m出任\u001b[0m \u001b[42m杭州\u001b[0m \u001b[39m、\u001b[0m \u001b[32m颍州\u001b[0m \u001b[39m等\u001b[0m \u001b[39m知州\u001b[0m \u001b[39m职务\u001b[0m \u001b[39m，\u001b[0m \u001b[39m官\u001b[0m \u001b[39m至\u001b[0m \u001b[39m礼部\u001b[0m \u001b[39m尚书\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s1) \u001b[35m绍圣\u001b[0m \u001b[44m元年\u001b[0m \u001b[39m（\u001b[0m \u001b[44m1094年\u001b[0m \u001b[39m）\u001b[0m \u001b[39m被\u001b[0m \u001b[39m哲宗\u001b[0m \u001b[39m贬谪\u001b[0m \u001b[39m至\u001b[0m \u001b[42m惠州\u001b[0m \u001b[39m、\u001b[0m \u001b[42m儋州\u001b[0m \u001b[39m（\u001b[0m \u001b[1;32m\u001b[46m海南岛\u001b[0m\u001b[0m \u001b[39m）\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s2) \u001b[35m元符\u001b[0m \u001b[33m三\u001b[0m \u001b[35m年\u001b[0m \u001b[39m（\u001b[0m \u001b[44m1100年\u001b[0m \u001b[39m）\u001b[0m \u001b[39m，\u001b[0m \u001b[39m宋徽宗\u001b[0m \u001b[39m即位\u001b[0m \u001b[39m，\u001b[0m \u001b[39m向\u001b[0m \u001b[39m太后\u001b[0m \u001b[39m垂帘听政\u001b[0m \u001b[39m，\u001b[0m \u001b[39m下诏\u001b[0m \u001b[39m让\u001b[0m \u001b[41m苏轼北\u001b[0m \u001b[39m还\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s3) \u001b[39m建中\u001b[0m \u001b[39m靖国\u001b[0m \u001b[44m元年\u001b[0m \u001b[39m（\u001b[0m \u001b[44m1101年\u001b[0m \u001b[39m）\u001b[0m \u001b[39m，\u001b[0m \u001b[34m夏天\u001b[0m \u001b[39m因\u001b[0m \u001b[39m冷饮\u001b[0m \u001b[39m过度\u001b[0m \u001b[39m，\u001b[0m \u001b[39m下痢\u001b[0m \u001b[39m不止\u001b[0m \u001b[39m，\u001b[0m \u001b[39m又\u001b[0m \u001b[39m误\u001b[0m \u001b[39m服\u001b[0m \u001b[39m黄芪\u001b[0m \u001b[39m，\u001b[0m \u001b[39m结果\u001b[0m \u001b[39m病情\u001b[0m \u001b[39m恶化\u001b[0m \u001b[39m，\u001b[0m \u001b[39m「\u001b[0m \u001b[39m齿间\u001b[0m \u001b[39m出血\u001b[0m \u001b[39m如\u001b[0m \u001b[39m蚯蚓\u001b[0m \u001b[39m者\u001b[0m \u001b[39m无数\u001b[0m \u001b[39m」\u001b[0m \u001b[39m，\u001b[0m \u001b[44m七月\u001b[0m \u001b[44m二十八日\u001b[0m \u001b[39m于\u001b[0m \u001b[34m\u001b[45m常州\u001b[0m\u001b[0m \u001b[34m\u001b[45m孙氏馆\u001b[0m\u001b[0m \u001b[39m病\u001b[0m \u001b[39m卒\u001b[0m \u001b[39m，\u001b[0m \u001b[35m享年\u001b[0m \u001b[33m六十四\u001b[0m \u001b[35m岁\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s4) \u001b[39m由\u001b[0m \u001b[39m弟\u001b[0m \u001b[41m苏辙\u001b[0m \u001b[39m归葬\u001b[0m \u001b[39m于\u001b[0m \u001b[39m郏县\u001b[0m \u001b[39m小\u001b[0m \u001b[1;32m\u001b[46m峨眉山\u001b[0m\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s5) \u001b[39m南宋\u001b[0m \u001b[39m宋孝宗\u001b[0m \u001b[39m追赠\u001b[0m \u001b[39m谥号\u001b[0m \u001b[39m「\u001b[0m \u001b[39m文忠\u001b[0m \u001b[39m」\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s6) \u001b[39m苏轼\u001b[0m \u001b[39m疲于\u001b[0m \u001b[39m应付\u001b[0m \u001b[39m新旧\u001b[0m \u001b[39m党争\u001b[0m \u001b[39m，\u001b[0m \u001b[39m遇事\u001b[0m \u001b[39m「\u001b[0m \u001b[39m如\u001b[0m \u001b[39m食\u001b[0m \u001b[39m内有蝇\u001b[0m \u001b[39m，\u001b[0m \u001b[39m吐\u001b[0m \u001b[39m之\u001b[0m \u001b[39m乃\u001b[0m \u001b[39m已\u001b[0m \u001b[39m」\u001b[0m \u001b[39m，\u001b[0m \u001b[41m苏轼\u001b[0m \u001b[39m既\u001b[0m \u001b[39m反对\u001b[0m \u001b[41m王安石\u001b[0m \u001b[39m比较\u001b[0m \u001b[39m急进\u001b[0m \u001b[39m的\u001b[0m \u001b[39m改革\u001b[0m \u001b[39m措施\u001b[0m \u001b[39m，\u001b[0m \u001b[39m也\u001b[0m \u001b[39m不\u001b[0m \u001b[39m同意\u001b[0m \u001b[39m旧\u001b[0m \u001b[39m党\u001b[0m \u001b[39m司马光\u001b[0m \u001b[39m尽\u001b[0m \u001b[39m废\u001b[0m \u001b[39m新法\u001b[0m \u001b[39m，\u001b[0m \u001b[39m所以\u001b[0m \u001b[39m虽然\u001b[0m \u001b[45m新党\u001b[0m \u001b[39m一直\u001b[0m \u001b[39m称\u001b[0m \u001b[41m苏轼为\u001b[0m \u001b[39m旧\u001b[0m \u001b[39m党\u001b[0m \u001b[39m，\u001b[0m \u001b[39m但\u001b[0m \u001b[39m其实\u001b[0m \u001b[39m他\u001b[0m \u001b[39m在\u001b[0m \u001b[39m新旧\u001b[0m \u001b[33m两\u001b[0m \u001b[39m党\u001b[0m \u001b[39m之间\u001b[0m \u001b[39m均受\u001b[0m \u001b[39m排斥\u001b[0m \u001b[39m，\u001b[0m \u001b[39m仕途\u001b[0m \u001b[39m坎坷\u001b[0m \u001b[39m，\u001b[0m \u001b[39m时常\u001b[0m \u001b[39m远\u001b[0m \u001b[39m贬\u001b[0m \u001b[39m外方\u001b[0m \u001b[39m，\u001b[0m \u001b[39m不过\u001b[0m \u001b[39m他\u001b[0m \u001b[39m在\u001b[0m \u001b[39m各地\u001b[0m \u001b[39m居官\u001b[0m \u001b[39m清正\u001b[0m \u001b[39m，\u001b[0m \u001b[39m为民\u001b[0m \u001b[39m兴利\u001b[0m \u001b[39m除弊\u001b[0m \u001b[39m，\u001b[0m \u001b[39m政绩\u001b[0m \u001b[39m颇\u001b[0m \u001b[39m善\u001b[0m \u001b[39m，\u001b[0m \u001b[39m口碑\u001b[0m \u001b[39m甚佳\u001b[0m \u001b[39m，\u001b[0m \u001b[42m杭州\u001b[0m \u001b[1;32m\u001b[46m西湖\u001b[0m\u001b[0m \u001b[39m的\u001b[0m \u001b[32m苏堤\u001b[0m \u001b[39m就\u001b[0m \u001b[39m是\u001b[0m \u001b[39m实证\u001b[0m \u001b[39m。\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nlp = CoreNLPClient(endpoint='http://140.109.19.191:9000', start_server=False)\n",
    "\n",
    "doc = nlp.annotate(docs[3]['DTEXT_CN'], properties={'ssplit.boundaryTokenRegex': '[。]|[!?！？]+',\n",
    "                                                    'pipelineLanguage': 'zh'\n",
    "#                                                  'segment.serDictionary': 'edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz,ddbc-person-segmenter.txt,cbdb-person-segmenter.txt',\n",
    "#                                                     'ner.additional.regexner.mapping': 'ddbc-person-regexner.txt,cbdb-person-regexner.txt'\n",
    "                                                   })\n",
    "\n",
    "for sent in doc.sentence:\n",
    "    print(f'(s{sent.sentenceIndex})', end=' ')\n",
    "    snp_pprint(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s0) \u001b[39m「\u001b[0m \u001b[39mPTT\u001b[0m \u001b[39m创世神\u001b[0m \u001b[39m」\u001b[0m \u001b[41m杜奕瑾\u001b[0m \u001b[39m创办\u001b[0m \u001b[39m的\u001b[0m \u001b[45m台湾\u001b[0m \u001b[45m人工\u001b[0m \u001b[45m智慧\u001b[0m \u001b[45m实验室\u001b[0m \u001b[39m推出\u001b[0m \u001b[39m「\u001b[0m \u001b[39m雅婷\u001b[0m \u001b[39m逐字稿\u001b[0m \u001b[39m」\u001b[0m \u001b[39mApp\u001b[0m \u001b[39m，\u001b[0m \u001b[39m已\u001b[0m \u001b[39m在\u001b[0m \u001b[39miOS\u001b[0m \u001b[39m与\u001b[0m \u001b[39mAndroid\u001b[0m \u001b[39m平台\u001b[0m \u001b[39m上\u001b[0m \u001b[39m线\u001b[0m \u001b[39m，\u001b[0m \u001b[39m官方\u001b[0m \u001b[39m表示\u001b[0m \u001b[39m能\u001b[0m \u001b[39m节省\u001b[0m \u001b[39m至少\u001b[0m \u001b[34m\u001b[43m60%\u001b[0m\u001b[0m \u001b[39m的\u001b[0m \u001b[39m听打\u001b[0m \u001b[39m时间\u001b[0m \u001b[39m，\u001b[0m \u001b[39m还\u001b[0m \u001b[39m听\u001b[0m \u001b[39m得\u001b[0m \u001b[39m懂\u001b[0m \u001b[1;40m台湾\u001b[0m \u001b[1;40m国语\u001b[0m \u001b[39m和\u001b[0m \u001b[39m中英\u001b[0m \u001b[39m夹杂\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s1) \u001b[39m根据\u001b[0m \u001b[39mApp\u001b[0m \u001b[39m官方\u001b[0m \u001b[39m介绍\u001b[0m \u001b[39m，\u001b[0m \u001b[39m由\u001b[0m \u001b[45m台湾\u001b[0m \u001b[45m人工\u001b[0m \u001b[45m智慧\u001b[0m \u001b[45m实验室\u001b[0m \u001b[39m（\u001b[0m \u001b[39mAILabs\u001b[0m \u001b[39m）\u001b[0m \u001b[39m推出\u001b[0m \u001b[39m的\u001b[0m \u001b[39m「\u001b[0m \u001b[45m雅婷\u001b[0m \u001b[45m逐字稿\u001b[0m \u001b[39m」\u001b[0m \u001b[39mApp\u001b[0m \u001b[39m除了\u001b[0m \u001b[39m能\u001b[0m \u001b[39m即时\u001b[0m \u001b[39m做\u001b[0m \u001b[39m语音\u001b[0m \u001b[39m转\u001b[0m \u001b[39m文字\u001b[0m \u001b[39m，\u001b[0m \u001b[39m也可以\u001b[0m \u001b[39m用来\u001b[0m \u001b[39m提升\u001b[0m \u001b[39m听障人\u001b[0m \u001b[39m沟通\u001b[0m \u001b[39m效率\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s2) \u001b[39m无论是\u001b[0m \u001b[39m记录\u001b[0m \u001b[39m生活\u001b[0m \u001b[39m大小事\u001b[0m \u001b[39m，\u001b[0m \u001b[39m或是\u001b[0m \u001b[39m记录\u001b[0m \u001b[39m访谈\u001b[0m \u001b[39m、\u001b[0m \u001b[39m课堂\u001b[0m \u001b[39m、\u001b[0m \u001b[39m会议\u001b[0m \u001b[39m内容\u001b[0m \u001b[39m，\u001b[0m \u001b[39m都\u001b[0m \u001b[39m可以\u001b[0m \u001b[39m精准\u001b[0m \u001b[39m且\u001b[0m \u001b[39m快速\u001b[0m \u001b[39m地\u001b[0m \u001b[39m达成\u001b[0m \u001b[39m原本\u001b[0m \u001b[39m需要\u001b[0m \u001b[39m花费\u001b[0m \u001b[33m大量\u001b[0m \u001b[39m时间\u001b[0m \u001b[39m才\u001b[0m \u001b[39m有的\u001b[0m \u001b[39m逐字稿\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s3) \u001b[39m脸\u001b[0m \u001b[39m书\u001b[0m \u001b[39m帐号\u001b[0m \u001b[39mShar\u001b[0m \u001b[39mYuan\u001b[0m \u001b[39m的\u001b[0m \u001b[34m\u001b[45m台湾\u001b[0m\u001b[0m \u001b[34m\u001b[45m人工\u001b[0m\u001b[0m \u001b[34m\u001b[45m智慧\u001b[0m\u001b[0m \u001b[34m\u001b[45m实验室\u001b[0m\u001b[0m \u001b[39m员工\u001b[0m \u001b[44m日前\u001b[0m \u001b[39m发文\u001b[0m \u001b[39m说明\u001b[0m \u001b[39m，\u001b[0m \u001b[39m透过\u001b[0m \u001b[39m「\u001b[0m \u001b[39m雅婷\u001b[0m \u001b[39m逐字稿\u001b[0m \u001b[39m」\u001b[0m \u001b[39m，\u001b[0m \u001b[39m听障\u001b[0m \u001b[39m人士\u001b[0m \u001b[39m可\u001b[0m \u001b[39m透过\u001b[0m \u001b[39m文字\u001b[0m \u001b[39m的\u001b[0m \u001b[39m方式\u001b[0m \u001b[39m理解\u001b[0m \u001b[35m\u001b[1;40m其他\u001b[0m\u001b[0m \u001b[39m人\u001b[0m \u001b[39m在说\u001b[0m \u001b[39m什么\u001b[0m \u001b[39m，\u001b[0m \u001b[39m媒体\u001b[0m \u001b[39m工作者\u001b[0m \u001b[39m或\u001b[0m \u001b[31m记者\u001b[0m \u001b[39m能\u001b[0m \u001b[39m即时\u001b[0m \u001b[39m生成\u001b[0m \u001b[39m访谈\u001b[0m \u001b[39m或\u001b[0m \u001b[39m会议\u001b[0m \u001b[39m逐字稿\u001b[0m \u001b[39m，\u001b[0m \u001b[31m老师\u001b[0m \u001b[39m也\u001b[0m \u001b[39m能\u001b[0m \u001b[39m快速\u001b[0m \u001b[39m生成\u001b[0m \u001b[39m课程\u001b[0m \u001b[39m文字档\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s4) \u001b[41m杜奕瑾\u001b[0m \u001b[44m今年\u001b[0m \u001b[39m初\u001b[0m \u001b[39m接受\u001b[0m \u001b[39m商业\u001b[0m \u001b[39m周刊\u001b[0m \u001b[39m采访\u001b[0m \u001b[39m时\u001b[0m \u001b[39m说\u001b[0m \u001b[39m，\u001b[0m \u001b[45m行政院\u001b[0m \u001b[39m政务\u001b[0m \u001b[31m委员\u001b[0m \u001b[41m唐\u001b[0m \u001b[39m凤\u001b[0m \u001b[39m为\u001b[0m \u001b[39m提倡\u001b[0m \u001b[39m政府\u001b[0m \u001b[39m资讯\u001b[0m \u001b[39m公开\u001b[0m \u001b[39m，\u001b[0m \u001b[39m常\u001b[0m \u001b[39m带\u001b[0m \u001b[39m著\u001b[0m \u001b[39m每\u001b[0m \u001b[39m分钟\u001b[0m \u001b[39m打字\u001b[0m \u001b[39m高达\u001b[0m \u001b[33m350\u001b[0m \u001b[39m字\u001b[0m \u001b[39m的\u001b[0m \u001b[39m速录师\u001b[0m \u001b[41m薛雅婷\u001b[0m \u001b[39m为\u001b[0m \u001b[39m会议\u001b[0m \u001b[39m制作\u001b[0m \u001b[39m逐\u001b[0m \u001b[39m字稿\u001b[0m \u001b[39m，\u001b[0m \u001b[39m因此\u001b[0m \u001b[45m台湾\u001b[0m \u001b[45m人工\u001b[0m \u001b[45m智慧\u001b[0m \u001b[45m实验室\u001b[0m \u001b[39m把\u001b[0m \u001b[39m内部\u001b[0m \u001b[39m开发\u001b[0m \u001b[39m的\u001b[0m \u001b[39m语音\u001b[0m \u001b[39m辨识\u001b[0m \u001b[39m系统\u001b[0m \u001b[39m取名\u001b[0m \u001b[39m为\u001b[0m \u001b[39m「\u001b[0m \u001b[39m雅婷\u001b[0m \u001b[33m一\u001b[0m \u001b[35m号\u001b[0m \u001b[39m」\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s5) \u001b[41m杜奕瑾\u001b[0m \u001b[39m在\u001b[0m \u001b[39m访谈\u001b[0m \u001b[39m中\u001b[0m \u001b[39m指出\u001b[0m \u001b[39m，\u001b[0m \u001b[39m国际\u001b[0m \u001b[39m大\u001b[0m \u001b[39m厂\u001b[0m \u001b[39m已\u001b[0m \u001b[39m把\u001b[0m \u001b[1;40m英文\u001b[0m \u001b[39m、\u001b[0m \u001b[1;40m中文\u001b[0m \u001b[39m语音\u001b[0m \u001b[39m辨识\u001b[0m \u001b[39m的\u001b[0m \u001b[39m应用\u001b[0m \u001b[39m做得\u001b[0m \u001b[39m很\u001b[0m \u001b[39m好\u001b[0m \u001b[39m，\u001b[0m \u001b[39m台商\u001b[0m \u001b[39m机会\u001b[0m \u001b[39m在于\u001b[0m \u001b[39m把\u001b[0m \u001b[39m本\u001b[0m \u001b[39m土腔\u001b[0m \u001b[39m调和\u001b[0m \u001b[39m特殊\u001b[0m \u001b[39m用语\u001b[0m \u001b[39m做\u001b[0m \u001b[39m得\u001b[0m \u001b[39m更\u001b[0m \u001b[39m精进\u001b[0m \u001b[39m。\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nlp = CoreNLPClient(endpoint='http://localhost:9000', start_server=False)\n",
    "\n",
    "doc = nlp.annotate(docs[27]['DTEXT_CN'], properties={'ssplit.boundaryTokenRegex': '[。]|[!?！？]+',\n",
    "#                                                  'segment.serDictionary': 'edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz,ddbc-person-segmenter.txt,cbdb-person-segmenter.txt',\n",
    "#                                                     'ner.additional.regexner.mapping': 'ddbc-person-regexner.txt,cbdb-person-regexner.txt'\n",
    "                                                   })\n",
    "\n",
    "for sent in doc.sentence:\n",
    "    print(f'(s{sent.sentenceIndex})', end=' ')\n",
    "    snp_pprint(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s0) \u001b[39m根据\u001b[0m \u001b[39m「\u001b[0m \u001b[39m悬浮\u001b[0m \u001b[39m微粒\u001b[0m \u001b[39m特征\u001b[0m \u001b[39m对\u001b[0m \u001b[39m民众\u001b[0m \u001b[39m健康\u001b[0m \u001b[39m影响\u001b[0m \u001b[39m之\u001b[0m \u001b[39m研究\u001b[0m \u001b[39m」\u001b[0m \u001b[39m，\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39m竟是\u001b[0m \u001b[39mPM2.5\u001b[0m \u001b[39m浓度\u001b[0m \u001b[39m暴露\u001b[0m \u001b[39m最\u001b[0m \u001b[39m高\u001b[0m \u001b[39m的\u001b[0m \u001b[39m交通\u001b[0m \u001b[39m工具\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s1) \u001b[45m行政院\u001b[0m \u001b[39m环境\u001b[0m \u001b[39m保护\u001b[0m \u001b[39m署\u001b[0m \u001b[44m今天\u001b[0m \u001b[39m表示\u001b[0m \u001b[39m，\u001b[0m \u001b[39m这\u001b[0m \u001b[39m项\u001b[0m \u001b[39m结果\u001b[0m \u001b[39m只是\u001b[0m \u001b[39m瞬间\u001b[0m \u001b[39m数值\u001b[0m \u001b[39m，\u001b[0m \u001b[39m平均\u001b[0m \u001b[39m浓度\u001b[0m \u001b[39m最\u001b[0m \u001b[39m高\u001b[0m \u001b[39m的\u001b[0m \u001b[39m仍然\u001b[0m \u001b[39m是\u001b[0m \u001b[39m机车\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s2) \u001b[45m环保署\u001b[0m \u001b[39m与\u001b[0m \u001b[45m国卫院\u001b[0m \u001b[45m国家\u001b[0m \u001b[45m环境\u001b[0m \u001b[45m医学\u001b[0m \u001b[45m研究所\u001b[0m \u001b[44m106年\u001b[0m \u001b[39m度\u001b[0m \u001b[39m针对\u001b[0m \u001b[39m针对\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39m、\u001b[0m \u001b[39m公车\u001b[0m \u001b[39m、\u001b[0m \u001b[39m汽车\u001b[0m \u001b[39m、\u001b[0m \u001b[39m机车\u001b[0m \u001b[39m、\u001b[0m \u001b[39m步行\u001b[0m \u001b[39m、\u001b[0m \u001b[39m脚踏车\u001b[0m \u001b[39m等\u001b[0m \u001b[33m6\u001b[0m \u001b[39m大\u001b[0m \u001b[39m交通\u001b[0m \u001b[39m方式\u001b[0m \u001b[39m，\u001b[0m \u001b[39m进行\u001b[0m \u001b[39m「\u001b[0m \u001b[39m悬浮\u001b[0m \u001b[39m微粒\u001b[0m \u001b[39m特征\u001b[0m \u001b[39m对\u001b[0m \u001b[39m民众\u001b[0m \u001b[39m健康\u001b[0m \u001b[39m影响\u001b[0m \u001b[39m之\u001b[0m \u001b[39m研究\u001b[0m \u001b[39m」\u001b[0m \u001b[39m，\u001b[0m \u001b[39m结果\u001b[0m \u001b[39m报告\u001b[0m \u001b[39m指出\u001b[0m \u001b[39m，\u001b[0m \u001b[39m细\u001b[0m \u001b[39m悬浮\u001b[0m \u001b[39m微粒\u001b[0m \u001b[39m（\u001b[0m \u001b[39mPM2.5\u001b[0m \u001b[39m）\u001b[0m \u001b[39m浓度\u001b[0m \u001b[39m暴露\u001b[0m \u001b[39m排名\u001b[0m \u001b[39m最高\u001b[0m \u001b[39m的\u001b[0m \u001b[39m竟是\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s3) \u001b[45m环保署\u001b[0m \u001b[39m空气\u001b[0m \u001b[39m品质\u001b[0m \u001b[39m保护\u001b[0m \u001b[39m及\u001b[0m \u001b[39m噪音\u001b[0m \u001b[39m管制\u001b[0m \u001b[39m处\u001b[0m \u001b[39m专门\u001b[0m \u001b[31m委员\u001b[0m \u001b[41m徐淑芷\u001b[0m \u001b[39m接受\u001b[0m \u001b[45m中央社\u001b[0m \u001b[31m记者\u001b[0m \u001b[39m访问\u001b[0m \u001b[39m时\u001b[0m \u001b[39m表示\u001b[0m \u001b[39m，\u001b[0m \u001b[41m国卫\u001b[0m \u001b[39m院\u001b[0m \u001b[39m使用\u001b[0m \u001b[39m的\u001b[0m \u001b[39m方式\u001b[0m \u001b[39m是\u001b[0m \u001b[39m以\u001b[0m \u001b[39m空气\u001b[0m \u001b[39m盒子\u001b[0m \u001b[39m进行\u001b[0m \u001b[39m测量\u001b[0m \u001b[39m，\u001b[0m \u001b[39m在\u001b[0m \u001b[39m定点\u001b[0m \u001b[39m容易\u001b[0m \u001b[39m受到\u001b[0m \u001b[39m周遭\u001b[0m \u001b[39m环境\u001b[0m \u001b[39m或\u001b[0m \u001b[39m瞬间\u001b[0m \u001b[39m污染\u001b[0m \u001b[39m，\u001b[0m \u001b[39m而\u001b[0m \u001b[39m呈现\u001b[0m \u001b[39m高值\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s4) \u001b[45m捷运\u001b[0m \u001b[45m测量\u001b[0m \u001b[45m处\u001b[0m \u001b[39m是\u001b[0m \u001b[39m在\u001b[0m \u001b[39m月台\u001b[0m \u001b[39m，\u001b[0m \u001b[39m列车\u001b[0m \u001b[39m进站\u001b[0m \u001b[39m时\u001b[0m \u001b[39m的\u001b[0m \u001b[39m状态\u001b[0m \u001b[39m，\u001b[0m \u001b[39m因为\u001b[0m \u001b[39m车刚\u001b[0m \u001b[39m进站\u001b[0m \u001b[39m会\u001b[0m \u001b[39m有\u001b[0m \u001b[33m一\u001b[0m \u001b[39m阵\u001b[0m \u001b[39m风\u001b[0m \u001b[39m，\u001b[0m \u001b[39m在\u001b[0m \u001b[39m地下\u001b[0m \u001b[39m化且\u001b[0m \u001b[39m没有\u001b[0m \u001b[39m闸门\u001b[0m \u001b[39m完全\u001b[0m \u001b[39m阻隔\u001b[0m \u001b[39m的\u001b[0m \u001b[39m站台\u001b[0m \u001b[39m，\u001b[0m \u001b[39m粉尘\u001b[0m \u001b[39m或\u001b[0m \u001b[39m微粒\u001b[0m \u001b[39m很\u001b[0m \u001b[39m容易\u001b[0m \u001b[39m因\u001b[0m \u001b[39m风\u001b[0m \u001b[39m而起\u001b[0m \u001b[39m，\u001b[0m \u001b[39m导致\u001b[0m \u001b[39m瞬间\u001b[0m \u001b[39m数值\u001b[0m \u001b[39m高升\u001b[0m \u001b[39m，\u001b[0m \u001b[39m与\u001b[0m \u001b[39m一般\u001b[0m \u001b[39m理解\u001b[0m \u001b[39m搭\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39m的\u001b[0m \u001b[39m观念\u001b[0m \u001b[39m不\u001b[0m \u001b[39m一样\u001b[0m \u001b[39m，\u001b[0m \u001b[39m并不\u001b[0m \u001b[39m是\u001b[0m \u001b[39m一直\u001b[0m \u001b[39m维持\u001b[0m \u001b[39m高\u001b[0m \u001b[39m浓度\u001b[0m \u001b[39m的\u001b[0m \u001b[39mPM2.5\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s5) \u001b[41m徐淑芷\u001b[0m \u001b[39m指出\u001b[0m \u001b[39m，\u001b[0m \u001b[39m虽然\u001b[0m \u001b[39m测量\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39mPM2.5\u001b[0m \u001b[39m浓度\u001b[0m \u001b[39m瞬间\u001b[0m \u001b[39m值\u001b[0m \u001b[39m容易\u001b[0m \u001b[39m升高\u001b[0m \u001b[39m，\u001b[0m \u001b[39m但\u001b[0m \u001b[39m因为\u001b[0m \u001b[39m民众\u001b[0m \u001b[39m不是\u001b[0m \u001b[39m长时间\u001b[0m \u001b[39m曝露\u001b[0m \u001b[39m，\u001b[0m \u001b[39m整体\u001b[0m \u001b[39m来\u001b[0m \u001b[39m看相\u001b[0m \u001b[39m较于\u001b[0m \u001b[35m\u001b[1;40m其他\u001b[0m\u001b[0m \u001b[39m交通\u001b[0m \u001b[39m工具\u001b[0m \u001b[39m而言\u001b[0m \u001b[39m还是\u001b[0m \u001b[39m低\u001b[0m \u001b[39m的\u001b[0m \u001b[39m；\u001b[0m \u001b[45m捷运\u001b[0m \u001b[45m公司\u001b[0m \u001b[39m也\u001b[0m \u001b[39m有\u001b[0m \u001b[39m定期\u001b[0m \u001b[39m清理\u001b[0m \u001b[39m轨道\u001b[0m \u001b[39m、\u001b[0m \u001b[39m集尘\u001b[0m \u001b[39m等\u001b[0m \u001b[39m，\u001b[0m \u001b[39m降低\u001b[0m \u001b[39m因\u001b[0m \u001b[39m风\u001b[0m \u001b[39m扬起\u001b[0m \u001b[39m粉尘\u001b[0m \u001b[39m的\u001b[0m \u001b[39m情况\u001b[0m \u001b[39m，\u001b[0m \u001b[39m在\u001b[0m \u001b[39m地面\u001b[0m \u001b[39m的\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39m车站\u001b[0m \u001b[39m虽然\u001b[0m \u001b[39m容易\u001b[0m \u001b[39m受到\u001b[0m \u001b[39m外界\u001b[0m \u001b[39m空气\u001b[0m \u001b[39m污染源\u001b[0m \u001b[39m影响\u001b[0m \u001b[39m，\u001b[0m \u001b[39m但\u001b[0m \u001b[39m不\u001b[0m \u001b[39m会\u001b[0m \u001b[39m有\u001b[0m \u001b[39m列车\u001b[0m \u001b[39m进站\u001b[0m \u001b[39m时\u001b[0m \u001b[39m因\u001b[0m \u001b[39m风\u001b[0m \u001b[39m瞬间\u001b[0m \u001b[39m扬起\u001b[0m \u001b[39m的\u001b[0m \u001b[39m粉尘\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s6) \u001b[39m监测\u001b[0m \u001b[39m结果\u001b[0m \u001b[39m，\u001b[0m \u001b[39m以\u001b[0m \u001b[39m骑乘\u001b[0m \u001b[39m机车\u001b[0m \u001b[39m通勤\u001b[0m \u001b[39mPM2.5\u001b[0m \u001b[39m暴露\u001b[0m \u001b[39m量\u001b[0m \u001b[39m平均\u001b[0m \u001b[39m浓度\u001b[0m \u001b[39m最高\u001b[0m \u001b[39m，\u001b[0m \u001b[39m因\u001b[0m \u001b[39m道路\u001b[0m \u001b[39m行驶\u001b[0m \u001b[39m时\u001b[0m \u001b[39m难以\u001b[0m \u001b[39m避免\u001b[0m \u001b[39m接近\u001b[0m \u001b[39m高\u001b[0m \u001b[39m污染\u001b[0m \u001b[39m车辆\u001b[0m \u001b[39m，\u001b[0m \u001b[39m致使\u001b[0m \u001b[39mPM2.5\u001b[0m \u001b[39m暴露\u001b[0m \u001b[39m量\u001b[0m \u001b[39m有\u001b[0m \u001b[39m瞬间\u001b[0m \u001b[39m攀升\u001b[0m \u001b[39m严重\u001b[0m \u001b[39m污染\u001b[0m \u001b[39m的\u001b[0m \u001b[39m情形\u001b[0m \u001b[39m；\u001b[0m \u001b[39m其次\u001b[0m \u001b[39m为\u001b[0m \u001b[39m公车\u001b[0m \u001b[39m，\u001b[0m \u001b[39m因为\u001b[0m \u001b[39m常\u001b[0m \u001b[39m处于\u001b[0m \u001b[39m主要\u001b[0m \u001b[39m交通\u001b[0m \u001b[39m要道\u001b[0m \u001b[39m，\u001b[0m \u001b[39m车门\u001b[0m \u001b[39m开启\u001b[0m \u001b[39m时\u001b[0m \u001b[39m车门\u001b[0m \u001b[39m外\u001b[0m \u001b[39m常\u001b[0m \u001b[39m受到\u001b[0m \u001b[39m摩托车\u001b[0m \u001b[39m围绕\u001b[0m \u001b[39m，\u001b[0m \u001b[39m使\u001b[0m \u001b[39m移动\u001b[0m \u001b[39m源\u001b[0m \u001b[39m污染物\u001b[0m \u001b[39m进入\u001b[0m \u001b[39m车厢\u001b[0m \u001b[39m；\u001b[0m \u001b[43m第三\u001b[0m \u001b[39m才\u001b[0m \u001b[39m是\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39m，\u001b[0m \u001b[39m会\u001b[0m \u001b[39m受\u001b[0m \u001b[39m站区\u001b[0m \u001b[39m或\u001b[0m \u001b[39m车厢\u001b[0m \u001b[39m的\u001b[0m \u001b[39m换气\u001b[0m \u001b[39m设备\u001b[0m \u001b[39m效能\u001b[0m \u001b[39m主导\u001b[0m \u001b[39m整体\u001b[0m \u001b[39m空气\u001b[0m \u001b[39m品质\u001b[0m \u001b[39m。\u001b[0m\n",
      "(s7) \u001b[41m徐淑芷\u001b[0m \u001b[39m强调\u001b[0m \u001b[39m，\u001b[0m \u001b[44m现在\u001b[0m \u001b[39m捷运\u001b[0m \u001b[39m车厢\u001b[0m \u001b[39m内\u001b[0m \u001b[39m的\u001b[0m \u001b[39m空气\u001b[0m \u001b[39m滤网\u001b[0m \u001b[39m、\u001b[0m \u001b[39m通风\u001b[0m \u001b[39m都\u001b[0m \u001b[39m做\u001b[0m \u001b[39m得\u001b[0m \u001b[39m很\u001b[0m \u001b[39m好\u001b[0m \u001b[39m，\u001b[0m \u001b[39m基本上\u001b[0m \u001b[39m车厢\u001b[0m \u001b[39m内\u001b[0m \u001b[39m的\u001b[0m \u001b[39m值\u001b[0m \u001b[39m都\u001b[0m \u001b[39m非常\u001b[0m \u001b[39m低\u001b[0m \u001b[39m；\u001b[0m \u001b[39m还是\u001b[0m \u001b[39m鼓励\u001b[0m \u001b[39m民众\u001b[0m \u001b[39m多\u001b[0m \u001b[39m使用\u001b[0m \u001b[39m大众\u001b[0m \u001b[39m运输\u001b[0m \u001b[39m工具\u001b[0m \u001b[39m，\u001b[0m \u001b[39m相较于\u001b[0m \u001b[39m骑\u001b[0m \u001b[39m机车\u001b[0m \u001b[39m、\u001b[0m \u001b[39m步行\u001b[0m \u001b[39m或\u001b[0m \u001b[39m脚踏车\u001b[0m \u001b[39m等\u001b[0m \u001b[39m，\u001b[0m \u001b[39m比较\u001b[0m \u001b[39m不\u001b[0m \u001b[39m会\u001b[0m \u001b[39m直接\u001b[0m \u001b[39m暴露\u001b[0m \u001b[39m在\u001b[0m \u001b[39m空气\u001b[0m \u001b[39m污染源\u001b[0m \u001b[39m中\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nlp = CoreNLPClient(endpoint='http://140.109.19.191:9000', start_server=False)\n",
    "\n",
    "doc = nlp.annotate(docs[25]['DTEXT_CN'], properties={'ssplit.boundaryTokenRegex': '[。]|[!?！？]+',\n",
    "                                                    'pipelineLanguage': 'zh'\n",
    "#                                                  'segment.serDictionary': 'edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz,ddbc-person-segmenter.txt,cbdb-person-segmenter.txt',\n",
    "#                                                     'ner.additional.regexner.mapping': 'ddbc-person-regexner.txt,cbdb-person-regexner.txt'\n",
    "                                                   })\n",
    "\n",
    "for sent in doc.sentence:\n",
    "    print(f'(s{sent.sentenceIndex})', end=' ')\n",
    "    snp_pprint(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
